{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSIS579_LAB_Lesson1_XOR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "D3QlsEiYR057",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network for logical XOR Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "o_ghiy3uR059",
        "colab_type": "text"
      },
      "source": [
        "In this lesson you will build a small neural network in Keras and train it to replicate the logical XOR function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "cwhArhP_R05-",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "VmFTtgahR05_",
        "colab_type": "code",
        "outputId": "f8a430f3-db21-4e4d-fae4-02926501ac41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%tensorflow_version 1.14\n",
        "%matplotlib inline\n",
        "from IPython.display import SVG\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense\n",
        "from keras.regularizers import l2\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(123)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(123)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.14`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "XAhW-JccR06G",
        "colab_type": "text"
      },
      "source": [
        "## Create dataset for the logical XOR function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "tI_AE4FnR06H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_X = np.array([[0, 0],\n",
        "                   [1, 0],\n",
        "                   [0, 1],\n",
        "                   [1, 1]])\n",
        "data_y = np.array([0, \n",
        "                   1, \n",
        "                   1, \n",
        "                   0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "Ur8-OukhR06K",
        "colab_type": "text"
      },
      "source": [
        "## Build the neural net model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "9-oc8QZ1R06L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(2, input_shape=(2,), activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "YA3nc0wsR06Q",
        "colab_type": "code",
        "outputId": "245dee44-353e-429a-d3cc-9dd6684f6207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 2)                 6         \n",
            "=================================================================\n",
            "Total params: 6\n",
            "Trainable params: 6\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "bnmBwvq9R06W",
        "colab_type": "text"
      },
      "source": [
        "# Question 1: \n",
        "How many parameters are there in the model so far? Why? Explain in detail what each parameter represents. Answer in the cell below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLKV0_3xR06X",
        "colab_type": "text"
      },
      "source": [
        "6 parameters. There are 2 input nodes, connected to 2 hidden nodes. This gives 2x2 = 4 weights. This accounts for 4 of the parameters.\n",
        "\n",
        "The other 2 parameters are the bias terms: one bias weight for each of the two hidden nodes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "e3-CNzAjR06Y",
        "colab_type": "text"
      },
      "source": [
        "## Add another layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "S5l_yKf6R06Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "mwCj-5F5R06c",
        "colab_type": "code",
        "outputId": "ee938035-f885-400a-f564-191b26f5cf10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "hvJYpNGuR06h",
        "colab_type": "text"
      },
      "source": [
        "## Question 2: \n",
        "How many new parameters are there now (e.g., how many were added after question 1)? Why? What does each new parameter represent? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpFyyzUcR06i",
        "colab_type": "text"
      },
      "source": [
        "There are 3 new parameters (for a total of 9). The new layer contains a single node, so each of the 2 previous hidden-layer nodes are connected to this single new node. That gives 2 regular weights. In addition, the new single node has a single bias node, connected to it with 1 weight. Hence there are 3 new weights in the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "z6VqwNQ2R06k",
        "colab_type": "text"
      },
      "source": [
        "## Visualize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "R2HcVRKvR06m",
        "colab_type": "code",
        "outputId": "aedac567-ccef-4f68-9925-456138d2d8e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "SVG(model_to_dot(model, show_shapes=True, dpi=65).create(prog='dot', format='svg'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"200pt\" viewBox=\"0.00 0.00 311.00 221.00\" width=\"281pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.9028 .9028) rotate(0) translate(4 217)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-217 307,-217 307,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139648455477120 -->\n<g class=\"node\" id=\"node1\">\n<title>139648455477120</title>\n<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 303,-212.5 303,-166.5 0,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-185.8\">dense_1_input: InputLayer</text>\n<polyline fill=\"none\" points=\"173,-166.5 173,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"173,-189.5 231,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"231,-166.5 231,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-197.3\">(None, 2)</text>\n<polyline fill=\"none\" points=\"231,-189.5 303,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-174.3\">(None, 2)</text>\n</g>\n<!-- 139648455476112 -->\n<g class=\"node\" id=\"node2\">\n<title>139648455476112</title>\n<polygon fill=\"none\" points=\"33,-83.5 33,-129.5 270,-129.5 270,-83.5 33,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-102.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"140,-83.5 140,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"140,-106.5 198,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"198,-83.5 198,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234\" y=\"-114.3\">(None, 2)</text>\n<polyline fill=\"none\" points=\"198,-106.5 270,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234\" y=\"-91.3\">(None, 2)</text>\n</g>\n<!-- 139648455477120&#45;&gt;139648455476112 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139648455477120-&gt;139648455476112</title>\n<path d=\"M151.5,-166.3799C151.5,-158.1745 151.5,-148.7679 151.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.0001,-139.784 151.5,-129.784 148.0001,-139.784 155.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139648455476616 -->\n<g class=\"node\" id=\"node3\">\n<title>139648455476616</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-46.5 270,-46.5 270,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"140,-.5 140,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"140,-23.5 198,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"198,-.5 198,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234\" y=\"-31.3\">(None, 2)</text>\n<polyline fill=\"none\" points=\"198,-23.5 270,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 139648455476112&#45;&gt;139648455476616 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139648455476112-&gt;139648455476616</title>\n<path d=\"M151.5,-83.3799C151.5,-75.1745 151.5,-65.7679 151.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"155.0001,-56.784 151.5,-46.784 148.0001,-56.784 155.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "FJcntixsR06r",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "6DPMHm__R06r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "3voJQXlpR06w",
        "colab_type": "text"
      },
      "source": [
        "### Modify the steps per epoch, number of epochs, etc. below as needed. The goal should be 100% accuracy for the XOR data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX8PQhoOR06x",
        "colab_type": "code",
        "outputId": "c2e1c5f5-90c3-43ee-f083-06979340e526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model.fit(data_X, data_y,\n",
        "          steps_per_epoch=500,\n",
        "          epochs=20)   # Note: different random initial conditions require different # of epochs. The output results in acc 1.000"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6978 - acc: 0.4970\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6793 - acc: 0.5805\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6096 - acc: 0.8220\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.4913 - acc: 1.0000\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.3834 - acc: 1.0000\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2997 - acc: 1.0000\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2368 - acc: 1.0000\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1892 - acc: 1.0000\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 0s 998us/step - loss: 0.1528 - acc: 1.0000\n",
            "Epoch 10/20\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1245 - acc: 1.0000\n",
            "Epoch 11/20\n",
            "500/500 [==============================] - 0s 983us/step - loss: 0.1022 - acc: 1.0000\n",
            "Epoch 12/20\n",
            "500/500 [==============================] - 0s 968us/step - loss: 0.0845 - acc: 1.0000\n",
            "Epoch 13/20\n",
            "500/500 [==============================] - 0s 955us/step - loss: 0.0701 - acc: 1.0000\n",
            "Epoch 14/20\n",
            "500/500 [==============================] - 0s 1000us/step - loss: 0.0585 - acc: 1.0000\n",
            "Epoch 15/20\n",
            "500/500 [==============================] - 0s 955us/step - loss: 0.0489 - acc: 1.0000\n",
            "Epoch 16/20\n",
            "500/500 [==============================] - 0s 972us/step - loss: 0.0410 - acc: 1.0000\n",
            "Epoch 17/20\n",
            "500/500 [==============================] - 0s 965us/step - loss: 0.0345 - acc: 1.0000\n",
            "Epoch 18/20\n",
            "500/500 [==============================] - 0s 963us/step - loss: 0.0291 - acc: 1.0000\n",
            "Epoch 19/20\n",
            "500/500 [==============================] - 0s 960us/step - loss: 0.0246 - acc: 1.0000\n",
            "Epoch 20/20\n",
            "500/500 [==============================] - 0s 960us/step - loss: 0.0208 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0234aa7588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "UTEsca_2R063",
        "colab_type": "text"
      },
      "source": [
        "# Run the trained model on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "pkQEQfisR064",
        "colab_type": "code",
        "outputId": "ede17fe0-19ea-45b4-90f0-f55504a67cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model.predict(data_X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01934543],\n",
              "       [0.9772504 ],\n",
              "       [0.98447406],\n",
              "       [0.01798293]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "_uWEq9owR069",
        "colab_type": "text"
      },
      "source": [
        "# Question 3:\n",
        "Explain the results of the predict() call above. How well did the trained model do on this problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-GgvoVYR06-",
        "colab_type": "text"
      },
      "source": [
        "The model is close to the desire results given in data_y (see following cell). The results are not exact because we have a sigmoid activation and will never output exactly 1 or 0. But if we consider a threshold of 0.5, setting the output to 1 if above threshold and 0 otherwise, then indeed the output is exactly [0,1,1,0] for the 4 inputs, as expected. Thus the network has solved the XOR problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tfCKNMCR07A",
        "colab_type": "code",
        "outputId": "465b5e5d-2968-47f8-8b6d-883cd0d584c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "locked": true,
          "solution": false
        },
        "id": "bo1huq3fR07J",
        "colab_type": "text"
      },
      "source": [
        "# Question 4:\n",
        "Print the weights of both layers of the trained network below. HINT: model.layers gives a list of layers. layer.get_weights() returns layer weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZY-JNqVR07K",
        "colab_type": "code",
        "outputId": "acfa1573-e9f2-4aa4-f436-88971a870d5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model.layers[0].get_weights()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-8.4953165, -7.9735317],\n",
              "        [ 8.583813 ,  7.392084 ]], dtype=float32),\n",
              " array([ 4.4691157, -4.0118427], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QMMDvL-R07Y",
        "colab_type": "code",
        "outputId": "82d5ed01-3ef4-4929-cb0d-a3b3324b5ec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.layers[1].get_weights()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-8.071775],\n",
              "        [ 8.60292 ]], dtype=float32), array([3.9016335], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vmW3UxER07c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}